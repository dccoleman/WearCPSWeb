---
title: "WearCPS: Safety vs. Security Analysis"
output: github_document
---

```{r setup, include=FALSE, echo = FALSE}
knitr::opts_chunk$set(echo = TRUE)
load("Pilot2.Rdata")

library(ggplot2)
library(pwr)
library(dplyr)
library(boot)

```

## Introduction

Below is the initial analyis/breakdown of the test data collected through our online pilot, **WearCPS.me**, through Amazon's Mechanical Turk

## Average Ages

Average ages of participants:

```{r, incude=TRUE, echo = FALSE}

summary(filterAge$age)

ggplot(filterAge, aes(x=age)) +  geom_dotplot() +
  scale_y_continuous(name = "", breaks = NULL) + ggtitle("Average Ages") +
  labs(x="Ages",y="Ages") 
```

## Score/Performance vs. Education Breakdown
```{r, incude=TRUE, echo = FALSE}

summary(filterEducationVsPerformance)

ggplot(filterEducationVsPerformance, aes(x=EducationLevel, y=FinalScore, fill=EducationLevel)) + stat_summary(fun.y="mean", geom="bar") + ggtitle("Education Level Vs Scores") +
  labs(x="Education Level",y="Scores") 

ggplot(filterEducationVsPerformance, aes(x=EducationLevel, y=NotificationCorrect, fill=EducationLevel)) + stat_summary(fun.y="mean", geom="bar") + ggtitle("Education Level Vs Notifications Correct") + labs(x="Education Level",y="Number Correct") 

```

## Avg. Score

PDF of Avg. Score:

```{r, incude=TRUE, echo = FALSE}

summary(filterScore)

ggplot(filterScore, aes(x=finalScore)) +  geom_density(kernel = "gaussian", fill='orange', alpha=0.25) + ggtitle("Avg. Score") + labs(x="Score", y ="Density") +
  scale_y_continuous(name = "", breaks = NULL)
```

## Avg. Response Time

PDF of Avg. Response Times:

```{r, incude=TRUE, echo = FALSE}

summary(filterResponseTimes)

x <- data.frame(Security=filterResponseTimes$secAvg,Safety=filterResponseTimes$safAvg)
library(ggplot2);library(reshape2)
data<- melt(x)
ggplot(data,aes(x=value, fill=variable)) + geom_density(alpha=0.25) + ggtitle("Response Times") + labs(x="Time(ms)", y ="Density") +
  scale_y_continuous(name = "", breaks = NULL)
```

## Notification Correctness

PDF of Avg. Notification Correctness:

```{r, incude=TRUE, echo = FALSE}

summary(filterNotificationResponseCorrectness)

x <- data.frame(Security=filterNotificationResponseCorrectness$secAvgCorrect,Safety=filterNotificationResponseCorrectness$safAvgCorrect)
library(ggplot2);library(reshape2)
data<- melt(x)
ggplot(data,aes(x=value, fill=variable)) + geom_density(alpha=0.25) + ggtitle("Notification Correctness") + labs(x="Percent Correct", y ="Density") +
  scale_y_continuous(name = "", breaks = NULL)

```

## Recall Correctness

PDF of Avg. Recall Correctness:

```{r, incude=TRUE, echo = FALSE}

summary(filterRecallCorrectness)

x <- data.frame(Security=filterRecallCorrectness$secPercent,Safety=filterRecallCorrectness$safPercent)
library(ggplot2);library(reshape2)
data<- melt(x)
ggplot(data,aes(x=value, fill=variable)) + geom_density(alpha=0.25) + ggtitle("Recall Correctness") + labs(x="Percent Correct", y ="Density") +
  scale_y_continuous(name = "", breaks = NULL)

```


## Confidence Intervals

### Response Times
Confidence intervals of the response times of safety vs. security.
```{r, include=TRUE, echo = FALSE}

# Bootstrap 95% CI for mean
# function to obtain mean from the data (with indexing)
mean.fun <- function(D, d) {
  return( mean(D[d]) )
}

data <- filterResponseTimesPerRow

# CI plot
# Example of usage: ciplot("myDependentVariable","myIndependentVariable") 
ciplot <- function(xVar, yVar) {
  
  groups <- group_by_(data, xVar)
  
  # Note: So far it is the only way found to enable variable name as string parameter for the function
  groupedData <- eval(parse(text=sprintf("summarize(groups, 
                                         mean=mean(%s),
                                         UCI=boot.ci(boot(%s, statistic = mean.fun, R=1000, sim=\"ordinary\"))$bca[,5],
                                         LCI=boot.ci(boot(%s, statistic = mean.fun, R=1000, sim=\"ordinary\"))$bca[,4])",
                                         yVar, yVar, yVar)))
  
  # Note: Another way to compute bootstrap CIs (boot library is used here instead), is to compute it mannually.
  # By adding mutate(se=sd/sqrt(n),lower=resp+qnorm(0.025)*se,upper=resp+qnorm(0.975)*se)
  df <- data.frame(
    trt = factor(groupedData[[1]]),
    resp = groupedData[["mean"]],
    group = factor(groupedData[[1]]),
    upper = c(groupedData[["UCI"]]),
    lower = c(groupedData[["LCI"]])
  )
 
  # Plot CI
  p <- ggplot(df, aes(trt, resp))
  p <- p + theme(axis.title=element_text(size=20), axis.text=element_text(size=18))
  p <- p + geom_pointrange(aes(ymin = lower, ymax = upper)) 
  p <- p + expand_limits(y = 0) 
  p <- p + ylab(yVar) 
  p <- p + xlab("") 
  p <- p + geom_errorbar(aes(ymin = lower, ymax = upper), width = 0.1) 
  #p <- p + coord_flip() #Can flip the coordinate here
  p
}


ciplot("Type", "ResponseTime")
summary(filterResponseTimesPerRow)
```

### Response Correctness
Confidence intervals of the response correctness of safety vs. security.
```{r, include=TRUE, echo = FALSE}
data <- filterNotificationResponseCorrectnessPerRow

ciplot("Type", "ResponseAnswer")
summary(filterNotificationResponseCorrectnessPerRow)

```

### Recall Correctness
Confidence intervals of the recall correctness of safety vs. security.
```{r, include=TRUE, echo = FALSE}
data <- filterRecallCorrectnessPerRow

ciplot("Type", "Answer")
summary(filterRecallCorrectnessPerRow)
```


## Primary Task Score Over Time

```{r, incude=TRUE, echo = FALSE}

summary(filterPrimaryTaskScoreTimes)

ggplot(filterPrimaryTaskScoreTimes, aes(x=filterPrimaryTaskScoreTimes$PrimaryTaskEntryTime, y=filterPrimaryTaskScoreTimes$Score)) +  geom_point() + ggtitle("Score Vs. Time") + labs(x="Time", y ="Score")

```

## Individual Trial

```{r, incude=TRUE, echo = FALSE}

summary(filterPrimaryTaskScoreTimes)

scoreData = subset(filterPrimaryTaskScoreTimes, ParticipantID=='A4J4GGMKJ68L0')


ggplot(scoreData, aes(x=scoreData$PrimaryTaskEntryTime, y=scoreData$Score)) +  geom_point() + ggtitle("Score Vs. Time") + labs(x="Time", y ="Score")

```

## Notification Grade Level Versus Response Correctness

Basic plot of response correctness against the reading grade level of the notification.

```{r, incude=TRUE, echo = FALSE}

summary(filterNotificationGradeLevels)

ggplot(filterNotificationGradeLevels, aes(x=GradeLevel, y=Correct, fill=GradeLevel, width=.5)) +  stat_summary(fun.y="mean", geom ="bar") + ggtitle("Grade Levels Vs Correctness") + labs(x="Grade Level", y ="Correctness")

```

## Power Analysis

### Response Time
This is the power analyis for the difference in response time between safety and security notifications. The first number is the power analysis of our results from the pilot. The second number represent the analysis we'd need to show a significant (2.5 seconds) difference in response times.
```{r, echo = FALSE}
# Example (breaking down the functions)
# Effect Size is the key. 
# While we have good estimates of variability from a given metric (like visited),
# the means of group 1 and 2 are something we should reason about.
# It's helpful to plug different means in (hypothetical means) to see how suggested "n" changes.
#
# Effect size is defined as:
# effectsize = abs(meangroup1 - meangroup2) / stdevofbothgroups
# abs( mean( fade$visited ) - mean( nofade$visited ) ) / sd( data$visited ), 
# We assume a power of 0.8 (a good estimate according to wikipedia)
# Then we plug those into the pwr.t.test function like:
# 
# desired <- pwr.t.test( 
#   d=effectsize # from above 
#   sig.level=.05, 
#   power=0.8, 
#   type="two.sample"  # changes if we do paired tests, or one sided
# )
# `desired` contains information about power, n, etcetera. We want `desired$n`
# A heuristic if your actual data are non-normal (given we are using tests for normal data) is to add 15% to n.
# Also, `desired$n` is initially the number in *each* group, so we need to multiply by 2
# desired$n * 1.15 * 2 # participants needed for a "safe" experiment given the means and stdev
#shinyApp(
#  
#  ui = fluidPage(
#    #  Application title
#    titlePanel("Interactive Power Analysis for Visited"),
#    
#    # Sidebar with sliders that demonstrate various available
#    # options
#    sidebarLayout(
#      sidebarPanel(
#        # Simple integer interval
#        sliderInput("group1", "Group1:", 
#                    min=0, max=50, value=mean(fade$visited)),
#        
#        sliderInput("group2", "Group2:", 
#                    min=0, max=50, value=mean(nofade$visited))
#      ),
#      
#      # Show a table summarizing the values entered
#      mainPanel(
#        tableOutput("values")
#      )
#  )),
#  
#  server = function(input, output) {
#    # Reactive expression to compose a data frame containing all of
#    # the values
#    sliderValues <- reactive({
#      
#      numParticipants <- pwr.t.test( 
#        d=abs(   mean(   input$group1 ) - 
#                 mean(   input$group2 ) ) / 
#                 14.28, 
#        sig.level=.05, 
#        power=0.8, 
#        type="two.sample" 
#      )$n * 1.15 * 2
#      
#      # Compose data frame
#      data.frame(
#        Name = c("group1", 
#                 "group2",
#                 "necessaryN"),
#        Value = as.character(c(input$group1, 
#                               input$group2,
#                               numParticipants)), 
#        stringsAsFactors=FALSE)
#    }) 
#    
#    # Show the values using an HTML table
#    output$values <- renderTable({
#      sliderValues()
#    })
#  },
#  
#  options = list(height = 500)
#)

safety <- subset(filterResponseTimesPerRow, Type=="Safety")
security <- subset(filterResponseTimesPerRow, Type=="Security")

# our current difference
pwr.t.test( 
  d=abs( mean(   safety$ResponseTime ) - 
         mean( security$ResponseTime ) ) / 
         sd(     filterResponseTimesPerRow$ResponseTime ), 
  sig.level=.05, 
  power=0.8, 
  type="two.sample" 
)$n * 1.15 * 2

# assuming a 2.5 second reliable difference
pwr.t.test( 
  d=abs( 2500 ) / 
         sd(     filterResponseTimesPerRow$ResponseTime ), 
  sig.level=.05, 
  power=0.8, 
  type="two.sample" 
)$n * 1.15 * 2

```

### Response Correctness

This is the power analyis for the difference in response correctness between safety and security notifications. The first number is the power analysis of our results from the pilot. The second number represent the analysis we'd need to show a significant (20%) difference in response correctness.

```{r, echo = FALSE}

safety2 <- subset(filterNotificationResponseCorrectnessPerRow, Type=="Safety")
security2 <- subset(filterNotificationResponseCorrectnessPerRow, Type=="Security")

# assuming a 25% reliable difference
pwr.t.test( 
  d=abs(mean(   safety2$ResponseAnswer ) - 
         mean( security2$ResponseAnswer )  / 
         sd(     filterNotificationResponseCorrectnessPerRow$ResponseAnswer )), 
  sig.level=.05, 
  power=0.8, 
  type="two.sample" 
)$n * 1.15 * 2

# assuming a 20% reliable difference
pwr.t.test( 
  d=abs(.2 / 
         sd(     filterNotificationResponseCorrectnessPerRow$ResponseAnswer )), 
  sig.level=.05, 
  power=0.8, 
  type="two.sample" 
)$n * 1.15 * 2

```
**Note** that the `echo = FALSE` parameter can be added to the code chunk to prevent printing of the R code that generates the plot.
